{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 2 - Adam "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import libraries + read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303893, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLANO, Texas, Dec. 8, 2020 /PRNewswire/ --Euro...</td>\n",
       "      <td>European Wax Center Welcomes Jennifer Vanderve...</td>\n",
       "      <td>2020-12-08 09:00:00-05:00</td>\n",
       "      <td>{'ticker': 'MIK', 'start_time': '2020-12-08 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHARLOTTE, N.C., Oct. 1, 2020 /PRNewswire/ --D...</td>\n",
       "      <td>Duke Energy to host virtual Environmental, Soc...</td>\n",
       "      <td>2020-10-01 12:11:00-04:00</td>\n",
       "      <td>{'ticker': 'DUK', 'start_time': '2020-10-01 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOUTH SAN FRANCISCO, Calif., Oct. 5, 2020 /PRN...</td>\n",
       "      <td>Pliant Therapeutics Appoints Mike Ouimette as ...</td>\n",
       "      <td>2020-10-05 08:00:00-04:00</td>\n",
       "      <td>{'ticker': 'PLRX', 'start_time': '2020-10-05 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW YORK, Jan. 18, 2021 /PRNewswire/ -- With a...</td>\n",
       "      <td>Radiofrequency Ablation Devices Market Revenue...</td>\n",
       "      <td>2021-01-18 02:30:00-05:00</td>\n",
       "      <td>{'ticker': ''}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENGLEWOOD, Colo., Feb. 22, 2021 /PRNewswire/ -...</td>\n",
       "      <td>DISH Network reports fourth quarter, year-end ...</td>\n",
       "      <td>2021-02-22 06:05:00-05:00</td>\n",
       "      <td>{'ticker': 'DISH', 'start_time': '2021-02-22 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  PLANO, Texas, Dec. 8, 2020 /PRNewswire/ --Euro...   \n",
       "1  CHARLOTTE, N.C., Oct. 1, 2020 /PRNewswire/ --D...   \n",
       "2  SOUTH SAN FRANCISCO, Calif., Oct. 5, 2020 /PRN...   \n",
       "3  NEW YORK, Jan. 18, 2021 /PRNewswire/ -- With a...   \n",
       "4  ENGLEWOOD, Colo., Feb. 22, 2021 /PRNewswire/ -...   \n",
       "\n",
       "                                               title  \\\n",
       "0  European Wax Center Welcomes Jennifer Vanderve...   \n",
       "1  Duke Energy to host virtual Environmental, Soc...   \n",
       "2  Pliant Therapeutics Appoints Mike Ouimette as ...   \n",
       "3  Radiofrequency Ablation Devices Market Revenue...   \n",
       "4  DISH Network reports fourth quarter, year-end ...   \n",
       "\n",
       "                    pub_time  \\\n",
       "0  2020-12-08 09:00:00-05:00   \n",
       "1  2020-10-01 12:11:00-04:00   \n",
       "2  2020-10-05 08:00:00-04:00   \n",
       "3  2021-01-18 02:30:00-05:00   \n",
       "4  2021-02-22 06:05:00-05:00   \n",
       "\n",
       "                                              labels  \n",
       "0  {'ticker': 'MIK', 'start_time': '2020-12-08 09...  \n",
       "1  {'ticker': 'DUK', 'start_time': '2020-10-01 12...  \n",
       "2  {'ticker': 'PLRX', 'start_time': '2020-10-05 0...  \n",
       "3                                     {'ticker': ''}  \n",
       "4  {'ticker': 'DISH', 'start_time': '2021-02-22 0...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from datetime import date\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_json('evaluate_news.json')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: finding the most important words \n",
    "We will find the most important words for positive and negative outcomes based on stocks. \n",
    "\n",
    "We will use 3 methods of feature engineering: TF-IDF via Transformer, TF-IDF via Vectorizer, and a bag-of-words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get the labels, normalize them, and concatenate to the dataframe. Then, add a new column for the overall baseline change from start day 1 to end of day 3.\n",
    "labels = df[\"labels\"]\n",
    "labels = pd.json_normalize(labels)\n",
    "data = pd.concat([df,labels],axis=1)\n",
    "data.dropna()\n",
    "data[\"baselinePctChng3\"] = ((data[\"end_price_3day\"] - data[\"start_price_open\"]) / data[\"start_price_open\"])*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>labels</th>\n",
       "      <th>ticker</th>\n",
       "      <th>start_time</th>\n",
       "      <th>start_price_open</th>\n",
       "      <th>start_price_close</th>\n",
       "      <th>end_price_1day</th>\n",
       "      <th>end_price_2day</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_time_1day</th>\n",
       "      <th>highest_time_2day</th>\n",
       "      <th>highest_time_3day</th>\n",
       "      <th>lowest_price_1day</th>\n",
       "      <th>lowest_price_2day</th>\n",
       "      <th>lowest_price_3day</th>\n",
       "      <th>lowest_time_1day</th>\n",
       "      <th>lowest_time_2day</th>\n",
       "      <th>lowest_time_3day</th>\n",
       "      <th>baselinePctChng3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLANO, Texas, Dec. 8, 2020 /PRNewswire/ --Euro...</td>\n",
       "      <td>European Wax Center Welcomes Jennifer Vanderve...</td>\n",
       "      <td>2020-12-08 09:00:00-05:00</td>\n",
       "      <td>{'ticker': 'MIK', 'start_time': '2020-12-08 09...</td>\n",
       "      <td>MIK</td>\n",
       "      <td>2020-12-08 09:00:00-05:00</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.4899</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-12-08 10:12:00-05:00</td>\n",
       "      <td>2020-12-08 10:12:00-05:00</td>\n",
       "      <td>2020-12-08 10:12:00-05:00</td>\n",
       "      <td>11.98</td>\n",
       "      <td>11.98</td>\n",
       "      <td>11.98</td>\n",
       "      <td>2020-12-08 09:13:00-05:00</td>\n",
       "      <td>2020-12-08 09:13:00-05:00</td>\n",
       "      <td>2020-12-08 09:13:00-05:00</td>\n",
       "      <td>7.705054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHARLOTTE, N.C., Oct. 1, 2020 /PRNewswire/ --D...</td>\n",
       "      <td>Duke Energy to host virtual Environmental, Soc...</td>\n",
       "      <td>2020-10-01 12:11:00-04:00</td>\n",
       "      <td>{'ticker': 'DUK', 'start_time': '2020-10-01 12...</td>\n",
       "      <td>DUK</td>\n",
       "      <td>2020-10-01 12:11:00-04:00</td>\n",
       "      <td>89.74</td>\n",
       "      <td>89.78</td>\n",
       "      <td>90.05</td>\n",
       "      <td>91.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-10-01 15:21:00-04:00</td>\n",
       "      <td>2020-10-02 15:32:00-04:00</td>\n",
       "      <td>2020-10-02 15:32:00-04:00</td>\n",
       "      <td>89.18</td>\n",
       "      <td>88.65</td>\n",
       "      <td>88.65</td>\n",
       "      <td>2020-10-01 14:03:00-04:00</td>\n",
       "      <td>2020-10-02 09:29:00-04:00</td>\n",
       "      <td>2020-10-02 09:29:00-04:00</td>\n",
       "      <td>2.518386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOUTH SAN FRANCISCO, Calif., Oct. 5, 2020 /PRN...</td>\n",
       "      <td>Pliant Therapeutics Appoints Mike Ouimette as ...</td>\n",
       "      <td>2020-10-05 08:00:00-04:00</td>\n",
       "      <td>{'ticker': 'PLRX', 'start_time': '2020-10-05 0...</td>\n",
       "      <td>PLRX</td>\n",
       "      <td>2020-10-05 09:29:00-04:00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.43</td>\n",
       "      <td>21.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-10-05 15:50:00-04:00</td>\n",
       "      <td>2020-10-06 09:35:00-04:00</td>\n",
       "      <td>2020-10-07 15:28:00-04:00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>2020-10-05 09:57:00-04:00</td>\n",
       "      <td>2020-10-05 09:57:00-04:00</td>\n",
       "      <td>2020-10-05 09:57:00-04:00</td>\n",
       "      <td>21.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW YORK, Jan. 18, 2021 /PRNewswire/ -- With a...</td>\n",
       "      <td>Radiofrequency Ablation Devices Market Revenue...</td>\n",
       "      <td>2021-01-18 02:30:00-05:00</td>\n",
       "      <td>{'ticker': ''}</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENGLEWOOD, Colo., Feb. 22, 2021 /PRNewswire/ -...</td>\n",
       "      <td>DISH Network reports fourth quarter, year-end ...</td>\n",
       "      <td>2021-02-22 06:05:00-05:00</td>\n",
       "      <td>{'ticker': 'DISH', 'start_time': '2021-02-22 0...</td>\n",
       "      <td>DISH</td>\n",
       "      <td>2021-02-22 06:09:00-05:00</td>\n",
       "      <td>34.25</td>\n",
       "      <td>34.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>30.8500</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-22 06:37:00-05:00</td>\n",
       "      <td>2021-02-22 06:37:00-05:00</td>\n",
       "      <td>2021-02-22 06:37:00-05:00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>29.71</td>\n",
       "      <td>29.71</td>\n",
       "      <td>2021-02-22 18:54:00-05:00</td>\n",
       "      <td>2021-02-23 12:09:00-05:00</td>\n",
       "      <td>2021-02-23 12:09:00-05:00</td>\n",
       "      <td>-8.321168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  PLANO, Texas, Dec. 8, 2020 /PRNewswire/ --Euro...   \n",
       "1  CHARLOTTE, N.C., Oct. 1, 2020 /PRNewswire/ --D...   \n",
       "2  SOUTH SAN FRANCISCO, Calif., Oct. 5, 2020 /PRN...   \n",
       "3  NEW YORK, Jan. 18, 2021 /PRNewswire/ -- With a...   \n",
       "4  ENGLEWOOD, Colo., Feb. 22, 2021 /PRNewswire/ -...   \n",
       "\n",
       "                                               title  \\\n",
       "0  European Wax Center Welcomes Jennifer Vanderve...   \n",
       "1  Duke Energy to host virtual Environmental, Soc...   \n",
       "2  Pliant Therapeutics Appoints Mike Ouimette as ...   \n",
       "3  Radiofrequency Ablation Devices Market Revenue...   \n",
       "4  DISH Network reports fourth quarter, year-end ...   \n",
       "\n",
       "                    pub_time  \\\n",
       "0  2020-12-08 09:00:00-05:00   \n",
       "1  2020-10-01 12:11:00-04:00   \n",
       "2  2020-10-05 08:00:00-04:00   \n",
       "3  2021-01-18 02:30:00-05:00   \n",
       "4  2021-02-22 06:05:00-05:00   \n",
       "\n",
       "                                              labels ticker  \\\n",
       "0  {'ticker': 'MIK', 'start_time': '2020-12-08 09...    MIK   \n",
       "1  {'ticker': 'DUK', 'start_time': '2020-10-01 12...    DUK   \n",
       "2  {'ticker': 'PLRX', 'start_time': '2020-10-05 0...   PLRX   \n",
       "3                                     {'ticker': ''}          \n",
       "4  {'ticker': 'DISH', 'start_time': '2021-02-22 0...   DISH   \n",
       "\n",
       "                  start_time  start_price_open  start_price_close  \\\n",
       "0  2020-12-08 09:00:00-05:00             12.07              12.07   \n",
       "1  2020-10-01 12:11:00-04:00             89.74              89.78   \n",
       "2  2020-10-05 09:29:00-04:00             20.00              20.00   \n",
       "3                        NaN               NaN                NaN   \n",
       "4  2021-02-22 06:09:00-05:00             34.25              34.25   \n",
       "\n",
       "   end_price_1day  end_price_2day  ...          highest_time_1day  \\\n",
       "0           12.80         12.4899  ...  2020-12-08 10:12:00-05:00   \n",
       "1           90.05         91.0000  ...  2020-10-01 15:21:00-04:00   \n",
       "2           21.43         21.9200  ...  2020-10-05 15:50:00-04:00   \n",
       "3             NaN             NaN  ...                        NaN   \n",
       "4           32.00         30.8500  ...  2021-02-22 06:37:00-05:00   \n",
       "\n",
       "           highest_time_2day          highest_time_3day lowest_price_1day  \\\n",
       "0  2020-12-08 10:12:00-05:00  2020-12-08 10:12:00-05:00             11.98   \n",
       "1  2020-10-02 15:32:00-04:00  2020-10-02 15:32:00-04:00             89.18   \n",
       "2  2020-10-06 09:35:00-04:00  2020-10-07 15:28:00-04:00             19.73   \n",
       "3                        NaN                        NaN               NaN   \n",
       "4  2021-02-22 06:37:00-05:00  2021-02-22 06:37:00-05:00             31.25   \n",
       "\n",
       "   lowest_price_2day  lowest_price_3day           lowest_time_1day  \\\n",
       "0              11.98              11.98  2020-12-08 09:13:00-05:00   \n",
       "1              88.65              88.65  2020-10-01 14:03:00-04:00   \n",
       "2              19.73              19.73  2020-10-05 09:57:00-04:00   \n",
       "3                NaN                NaN                        NaN   \n",
       "4              29.71              29.71  2021-02-22 18:54:00-05:00   \n",
       "\n",
       "            lowest_time_2day           lowest_time_3day baselinePctChng3  \n",
       "0  2020-12-08 09:13:00-05:00  2020-12-08 09:13:00-05:00         7.705054  \n",
       "1  2020-10-02 09:29:00-04:00  2020-10-02 09:29:00-04:00         2.518386  \n",
       "2  2020-10-05 09:57:00-04:00  2020-10-05 09:57:00-04:00        21.750000  \n",
       "3                        NaN                        NaN              NaN  \n",
       "4  2021-02-23 12:09:00-05:00  2021-02-23 12:09:00-05:00        -8.321168  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303893, 27)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sample\n",
    "dataShuffled = data.sample(frac=1)\n",
    "dataPos = dataShuffled[dataShuffled[\"baselinePctChng3\"] > 0]\n",
    "dataNeg = dataShuffled[dataShuffled[\"baselinePctChng3\"] < 0]\n",
    "\n",
    "posX = dataPos.sample(frac = 10000/57031, random_state=1)\n",
    "negX = dataNeg.sample(frac = 10000/48955,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>technological</th>\n",
       "      <td>0.333493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advancement</th>\n",
       "      <td>0.330038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innovations</th>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.283734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction</th>\n",
       "      <td>0.280454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engagement</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engaged</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engage20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engage</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zynlonta</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19862 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tfidf\n",
       "technological  0.333493\n",
       "advancement    0.330038\n",
       "innovations    0.303571\n",
       "model          0.283734\n",
       "construction   0.280454\n",
       "...                 ...\n",
       "engagement     0.000000\n",
       "engaged        0.000000\n",
       "engage20       0.000000\n",
       "engage         0.000000\n",
       "zynlonta       0.000000\n",
       "\n",
       "[19862 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF with transformer\n",
    "\n",
    "sentencesPositive = []\n",
    "wordsPositive = []\n",
    "\n",
    "for index, row in posX.iterrows():\n",
    "    sentence = row['title']\n",
    "    sentencesPositive.append(sentence)\n",
    "\n",
    "print(len(sentencesPositive))\n",
    "\n",
    "countVector = CountVectorizer()\n",
    "wordCountVector = countVector.fit_transform(sentencesPositive)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(wordCountVector)\n",
    "\n",
    "matrix = countVector.transform(sentencesPositive)\n",
    "tf_idf_vector=tfidf_transformer.transform(matrix)\n",
    "\n",
    "feature_names = countVector.get_feature_names_out() \n",
    "first_document_vector=tf_idf_vector[0] \n",
    "\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict = dict(zip(df.index, df['tfidf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>technological</th>\n",
       "      <td>0.333493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advancement</th>\n",
       "      <td>0.330038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innovations</th>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.283734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction</th>\n",
       "      <td>0.280454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engagement</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engaged</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engage20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engage</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zynlonta</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19862 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tfidf\n",
       "technological  0.333493\n",
       "advancement    0.330038\n",
       "innovations    0.303571\n",
       "model          0.283734\n",
       "construction   0.280454\n",
       "...                 ...\n",
       "engagement     0.000000\n",
       "engaged        0.000000\n",
       "engage20       0.000000\n",
       "engage         0.000000\n",
       "zynlonta       0.000000\n",
       "\n",
       "[19862 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF with vectorizer\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "# settings that you use for count vectorizer will go here \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True) \n",
    "\n",
    "#transform, send in\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(sentencesPositive)\n",
    "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0] \n",
    "\n",
    "#place in dataframe, sort by highest weight.\n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names_out(), columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clarus</th>\n",
       "      <td>0.420881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jury</th>\n",
       "      <td>0.402951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infringement</th>\n",
       "      <td>0.380360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lipocine</th>\n",
       "      <td>0.372298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patent</th>\n",
       "      <td>0.304175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empowerment</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empowering</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empowered</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empower</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyris</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20054 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfidf\n",
       "clarus        0.420881\n",
       "jury          0.402951\n",
       "infringement  0.380360\n",
       "lipocine      0.372298\n",
       "patent        0.304175\n",
       "...                ...\n",
       "empowerment   0.000000\n",
       "empowering    0.000000\n",
       "empowered     0.000000\n",
       "empower       0.000000\n",
       "zyris         0.000000\n",
       "\n",
       "[20054 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF with transformer\n",
    "sentencesNegative = []\n",
    "wordsPositive = []\n",
    "\n",
    "for index, row in negX.iterrows():\n",
    "    sentence = row['title']\n",
    "    sentencesNegative.append(sentence)\n",
    "\n",
    "print(len(sentencesNegative))\n",
    "\n",
    "countVector = CountVectorizer()\n",
    "wordCountVector = countVector.fit_transform(sentencesNegative)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(wordCountVector)\n",
    "\n",
    "matrix = countVector.transform(sentencesNegative)\n",
    "tf_idf_vector=tfidf_transformer.transform(matrix)\n",
    "\n",
    "feature_names = countVector.get_feature_names_out() \n",
    "first_document_vector=tf_idf_vector[0] \n",
    "\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "negDict = dict(zip(df.index, df['tfidf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clarus</th>\n",
       "      <td>0.420881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jury</th>\n",
       "      <td>0.402951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infringement</th>\n",
       "      <td>0.380360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lipocine</th>\n",
       "      <td>0.372298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patent</th>\n",
       "      <td>0.304175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empowerment</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empowering</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empowered</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empower</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyris</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20054 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfidf\n",
       "clarus        0.420881\n",
       "jury          0.402951\n",
       "infringement  0.380360\n",
       "lipocine      0.372298\n",
       "patent        0.304175\n",
       "...                ...\n",
       "empowerment   0.000000\n",
       "empowering    0.000000\n",
       "empowered     0.000000\n",
       "empower       0.000000\n",
       "zyris         0.000000\n",
       "\n",
       "[20054 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF with vectorizer\n",
    "\n",
    "# settings that you use for count vectorizer will go here \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True) \n",
    "\n",
    "# just send in all your docs here \n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(sentencesNegative)\n",
    "# get the first vector out (for the first document) \n",
    "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0] \n",
    "\n",
    "# place tf-idf values in a pandas data frame \n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names_out(), columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #most important words without TF-IDF\n",
    "# nltk.download('stopwords')\n",
    "# stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# cleanSentences = []\n",
    "# importantWords = []\n",
    "# for sentence in sentencesPositive: #SWAP FOR SENTENCESNEGATIVE.\n",
    "#     words = sentence.split()\n",
    "#     filteredWords = [word for word in words if word.lower() not in stopWords]\n",
    "#     cleanSentence = ' '.join(filteredWords)\n",
    "#     cleanSentences.append(cleanSentence)\n",
    "\n",
    "\n",
    "# wordCounter = {}\n",
    "# for sentence in cleanSentences:\n",
    "#     words = sentence.split()\n",
    "#     word_scores = {}\n",
    "#     for word in words:\n",
    "#         # Calculate word score as the product of its frequency and length\n",
    "#         score = len(word) * words.count(word)\n",
    "#         word_scores[word] = score\n",
    "#     most_important_word = max(word_scores, key=word_scores.get)\n",
    "#     if most_important_word in wordCounter:\n",
    "#         wordCounter[most_important_word] += 1\n",
    "#     else:\n",
    "#         wordCounter[most_important_word] = 1\n",
    "\n",
    "# for sentence, count in wordCounter.items():\n",
    "#     print(f\"{sentence}: {count}\")\n",
    "\n",
    "\n",
    "# # Remove key-value pairings where the key contains the substring \".com\"\n",
    "# to_delete = []\n",
    "# for key in wordCounter.keys():\n",
    "#     if \".com\" in key or \"https:\" in key:\n",
    "#         to_delete.append(key)\n",
    "# for key in to_delete:\n",
    "#     del wordCounter[key]\n",
    "\n",
    "\n",
    "# top_words = sorted(wordCounter.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# print(top_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bag of words model was producing values that were not valid / comparable, as such, it has been commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsInBoth = []\n",
    "for key in posDict.keys():\n",
    "    if key in negDict.keys() and posDict[key] > 0.2 and negDict[key] > 0.1:\n",
    "        wordsInBoth.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(wordsInBoth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across multiple runs, only Therapeutics and 1 other word appears on both with a threshold of 0.1 / 1.0 . A score of 0.1 is very small, so this means there isn't a very clear cut answer to what is positive or negative based on purely features and the TF-IDF scores on both + / - results.\n",
    "\n",
    "One major consideration is that each word comes from a different industry; one could extrapolate the causation when referring back to the original media and seeing what type of the 11 reports it was."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - validating results using a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using an SVM model to determine whether a simple model can determine whether a word's presence is likely to be positive or negative, or is correlated with outside factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import gensim.downloader as api\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. the strings are too long to be directly converted to floats, so the gensim library will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(string):\n",
    "    string = string.lower()\n",
    "\n",
    "    # remove punctuation using regex\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    \n",
    "    # tokenize the string\n",
    "    tokens = string.split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # join the filtered stuff back into a string\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to Split!\n",
      "Accuracy: 0.5225\n",
      "Precision: 0.5285857572718154\n",
      "Recall: 0.5207509881422925\n",
      "F1 score: 0.5246391239422598\n"
     ]
    }
   ],
   "source": [
    "#determine number of samples of + and -\n",
    "numSamples = 5000\n",
    "X = dataPos.sample(frac = numSamples/57031, random_state=1)\n",
    "Y = dataNeg.sample(frac = numSamples/48955,random_state=1)\n",
    "\n",
    "#we create labels for + / - outcomes as a binary 0/1.\n",
    "XLabel = np.ones((numSamples,), dtype=int)\n",
    "YLabel = np.zeros((numSamples,), dtype=int)\n",
    "\n",
    "XLabel = XLabel.tolist()\n",
    "YLabel = YLabel.tolist()\n",
    "\n",
    "labels = XLabel + YLabel\n",
    "\n",
    "\n",
    "modelSentences = []\n",
    "\n",
    "#here we pre-process, cleaning the titles and appending back to a list.\n",
    "for index, row in X.iterrows():\n",
    "    tempsent = row['title']\n",
    "    tempsent = cleaning(tempsent)\n",
    "    modelSentences.append(tempsent)\n",
    "\n",
    "for index, row in Y.iterrows():\n",
    "    tempsent = row['title']\n",
    "    tempsent = cleaning(tempsent)\n",
    "    modelSentences.append(tempsent)\n",
    "\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# Feature extraction\n",
    "embedding_dim = 100\n",
    "Z = np.zeros((len(modelSentences), embedding_dim))\n",
    "\n",
    "for i, title in enumerate(modelSentences):\n",
    "    vectors = [model.get_vector(word) for word in title if word in model.key_to_index]\n",
    "    if vectors:\n",
    "        Z[i, :] = np.mean(vectors, axis=0)\n",
    "        \n",
    "print(\"About to Split!\")\n",
    "\n",
    "#actual modelling\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# modelVectorizer = vectorizer.fit_transform(modelSentences)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(modelSentences, labels, test_size=0.2, random_state=42)\n",
    "# clf = SVC(kernel='linear')\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4945\n",
      "Precision: 0.5028901734104047\n",
      "Recall: 0.08596837944664032\n",
      "F1 score: 0.1468354430379747\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Z, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
